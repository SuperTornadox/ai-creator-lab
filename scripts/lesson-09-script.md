# Lesson 9: AI Truth Challenge -- Teacher Script
# 第九课：AI 真相挑战 -- 教师逐字稿

**Duration / 时长**: 40--45 minutes / 分钟
**Materials / 材料**: Slides (`slides.html`), Interactive webpage (`index.html`), Student laptops, Optional: a deepfake video clip to play during warm-up (pre-screened for age-appropriateness)
**Goal / 目标**: Students learn to critically evaluate AI-generated content by distinguishing real vs AI images, human vs AI writing, and testing AI for hidden biases.
**目标**: 学生通过辨别真实与 AI 图像、人类与 AI 文本、以及测试 AI 的隐藏偏见，学会批判性地评估 AI 生成的内容。

---

## Pre-Class Preparation / 课前准备

> **Important / 重要:**
>
> **Deepfake video (optional):**
> - Find a short (30-60 second), age-appropriate deepfake demo video online. Good options include well-known public figures in obviously fake but convincing scenarios (e.g., a celebrity "singing" a song they never sang, or a historical figure "speaking" in modern language).
> - Pre-screen the video to make sure it is appropriate for 12-year-olds. Avoid anything political, scary, or misleading about real events.
> - If you cannot find a suitable video, the slides have enough content to run the warm-up without one.
>
> **Sensitivity note:**
> - This lesson touches on AI bias, including gender and cultural stereotypes. Frame these as problems *with the data and systems*, not with any group of people.
> - Emphasize that bias is something we can notice, name, and work to fix -- it is not something to feel guilty about.
> - If students share personal experiences with bias, listen supportively and redirect to the systemic/technical angle.
>
> **课前准备 Deepfake 视频（可选）：**
> - 找一个短的（30-60秒）、适合年龄的 deepfake 演示视频。好的选择包括在明显虚假但令人信服的场景中的知名公众人物。
> - 预先筛选确保适合12岁学生。避免任何政治性的、恐怖的，或关于真实事件的误导性内容。
> - 如果找不到合适的视频，幻灯片有足够的内容来进行热身。
>
> **敏感话题提示：**
> - 这节课涉及 AI 偏见，包括性别和文化刻板印象。把这些描述为数据和系统的问题，而不是任何群体的问题。
> - 强调偏见是我们可以注意到、指出并努力修正的东西——不是让人感到内疚的东西。
> - 如果学生分享关于偏见的个人经历，要支持性地倾听，并引导回技术/系统层面的讨论。

---

## Warm-up / 概念热身 (10 minutes / 分钟)

### [SLIDE 1 -- Title] *(0:00)*

EN: "Welcome to AI Creator Lab! Today is a little different from our usual lessons. Today is not about creating with AI -- today is about OUTSMARTING AI. We're going to test whether you can tell the difference between things that are real and things that AI made up."

CN: "欢迎来到 AI 创造者实验室！今天和我们平常的课有点不同。今天不是关于用 AI 创作——今天是关于智胜 AI。我们要测试你能不能分辨出真实的东西和 AI 编造的东西之间的区别。"

**[Optional: Play deepfake video here / 可选：在此播放 deepfake 视频]**

EN: *(If showing video)* "Before we start, watch this short clip. Pay close attention. Is this real?"

CN: *(如果播放视频)* "在我们开始之前，看这段短片。仔细看。这是真的吗？"

**[After video, pause for reactions / 视频后，停顿等待反应]**

EN: *(If showing video)* "That was a DEEPFAKE -- completely generated by AI. The person never actually said or did that. Pretty convincing, right? That's exactly why today's lesson matters."

CN: *(如果播放视频)* "那是一个深度伪造——完全由 AI 生成的。那个人从来没有真正说过或做过那些。相当令人信服，对吧？这正是为什么今天的课很重要。"

---

### [SLIDE 2 -- Quick Poll] *(0:02)*

EN: "Quick poll: Can you ALWAYS tell if something was made by AI? Raise your hand if you think 'Yes, always.' Raise your hand for 'Sometimes.' And 'Not really.'"

CN: "快速投票：你能永远分辨出某样东西是不是 AI 做的吗？如果你觉得'是的，总是能'，举手。觉得'有时候能'的。觉得'不太能'的。"

**[Count hands, acknowledge responses / 数举手人数，回应]**

EN: "Interesting! The truth is, it's getting harder and harder. AI is improving incredibly fast. A year ago, AI images had obvious problems. Now? It's really tough sometimes. That's why we need to become smart digital detectives."

CN: "有意思！事实是，越来越难了。AI 进步得非常快。一年前，AI 图像有明显的问题。现在？有时候真的很难分辨。这就是为什么我们需要成为聪明的数字侦探。"

---

### [SLIDE 3 -- Deepfakes Explained] *(0:04)*

EN: "So what are deepfakes? Deepfakes are images, videos, or even audio that AI creates to look and sound incredibly real -- but they're completely fake. AI can now generate photos of people who have never existed. It can make videos of real people appearing to say things they never said. It can even clone someone's voice."

CN: "那什么是深度伪造？深度伪造是 AI 创建的图像、视频、甚至音频，看起来和听起来非常真实——但它们完全是假的。AI 现在可以生成从未存在过的人的照片。它可以制作真人看起来在说他们从未说过的话的视频。它甚至可以克隆某人的声音。"

EN: "This is incredible technology, but it can also be used to trick people. That's why we need to learn how to spot the fakes."

CN: "这是令人难以置信的技术，但它也可以被用来欺骗人。这就是为什么我们需要学会如何识别假货。"

---

### [SLIDE 4 -- Spotting Fake Images] *(0:05)*

EN: "Let's start with images. AI images are getting really good, but they still leave clues. Here are the biggest ones to watch for:"

CN: "让我们从图片开始。AI 图片越来越好了，但它们仍然会留下线索。以下是要注意的最大线索："

EN: "Number one: hands and fingers. AI often gives people extra fingers or bends fingers in weird ways. Number two: eyes -- sometimes they're different sizes or have strange reflections. Number three: text in images. If there's a sign or a book in the picture, AI usually gets the letters wrong -- they look like jumbled nonsense. Number four: things look TOO perfect. Impossibly smooth skin, no wrinkles, no blemishes. And number five: backgrounds. Look for things that melt together, impossible architecture, or objects that don't quite make sense."

CN: "第一：手和手指。AI 经常给人多余的手指或以奇怪的方式弯曲手指。第二：眼睛——有时它们大小不同或有奇怪的反射。第三：图像中的文字。如果图中有标志或书，AI 通常会把字母搞错——看起来像乱七八糟的胡话。第四：东西看起来太完美了。不可能的光滑皮肤，没有皱纹，没有瑕疵。第五：背景。寻找融合在一起的东西、不可能的建筑、或不太合理的物体。"

---

### [SLIDE 5 -- Spotting AI Writing] *(0:07)*

EN: "Now, text. AI can write essays, stories, and social media posts. Here's how you tell the difference."

CN: "现在说说文字。AI 可以写文章、故事和社交媒体帖子。以下是如何区分的。"

EN: "Human writing has personality. It has personal stories, messy details, casual language, maybe even slang or typos. Humans have strong opinions and emotions. AI writing is different -- it's polished, formal, perfectly organized. It avoids controversy, never takes a strong side, and reads like a textbook. AI text is correct, but it's often... boring."

CN: "人类写作有个性。它有个人故事、凌乱的细节、随意的语言，甚至可能有俚语或错别字。人类有强烈的观点和情感。AI 写作不同——它很精致、正式、组织完美。它避免争议，从不选择明确的立场，读起来像教科书。AI 文本是正确的，但通常……很无聊。"

---

### [SLIDE 6 -- What Is AI Bias?] *(0:08)*

EN: "Now the third big topic: AI bias. Bias means unfairly favoring or disfavoring certain groups of people. Here's the thing -- AI learns everything from data created by humans. If that data contains stereotypes, the AI picks them up."

CN: "现在第三个大话题：AI 偏见。偏见意味着不公平地偏袒或歧视某些群体。问题是——AI 从人类创建的数据中学习一切。如果那些数据包含刻板印象，AI 就会学到它们。"

EN: "For example, if you ask AI to 'describe a CEO,' it might always imagine a man in a suit. Why? Because most of the text it learned from described CEOs that way. But CEOs can be anyone! That's bias -- and AI can make it worse if we're not careful."

CN: "例如，如果你让 AI '描述一个CEO'，它可能总是想象一个穿西装的男人。为什么？因为它学习的大多数文本都是这样描述CEO的。但 CEO 可以是任何人！这就是偏见——如果我们不小心，AI 可以让它变得更糟。"

---

### [SLIDE 7 -- Where Does Bias Come From?] *(0:09)*

EN: "Here's how it works. Step one: AI is trained on billions of texts written by people. Step two: AI learns patterns from that text -- including stereotypes and biases. Step three: When AI generates new content, it may repeat those same unfair assumptions."

CN: "它是这样运作的。第一步：AI 在人们写的数十亿文本上训练。第二步：AI 从那些文本中学习模式——包括刻板印象和偏见。第三步：当 AI 生成新内容时，它可能会重复那些相同的不公平假设。"

EN: "The key thing to understand: this isn't because AI is 'bad.' It's because it mirrors what people have written. And people have biases. So we need to be aware of it."

CN: "关键要理解的是：这不是因为 AI 是'坏的'。而是因为它反映了人们写的东西。而人们有偏见。所以我们需要意识到这一点。"

---

### [SLIDE 8 -- Why Does This Matter?] *(0:09)*

**[Brief -- keep this to about 30 seconds / 简短——保持约30秒]**

EN: "Why does this matter? Because AI is being used for real decisions. Fake news articles created by AI can spread false information that millions of people believe. Biased AI hiring tools might reject qualified people because of their name or background. And AI that repeats stereotypes reinforces them instead of challenging them."

CN: "这为什么重要？因为 AI 正在被用于真实的决策。由 AI 创建的假新闻文章可以传播数百万人相信的虚假信息。有偏见的 AI 招聘工具可能会因为名字或背景而拒绝合格的人。重复刻板印象的 AI 会强化它们而不是挑战它们。"

---

### [SLIDE 9 -- Be a Smart Detective] *(0:09)*

EN: "So here's your toolkit for being a smart AI detective. One: question everything -- could this be AI-made? Two: check the source -- where did this come from? Is it a reliable website? Three: look for clues -- weird hands, too-perfect text, no personality. Four: cross-check facts with other reliable sources. Five: think about bias -- is this showing only one perspective?"

CN: "所以这是你成为聪明 AI 侦探的工具包。一：质疑一切——这可能是 AI 做的吗？二：检查来源——这来自哪里？是可靠的网站吗？三：寻找线索——奇怪的手、太完美的文字、没有个性。四：用其他可靠来源交叉检查事实。五：思考偏见——这是否只展示了一个角度？"

---

### [SLIDE 10 -- Your Mission] *(0:10)*

EN: "Now it's YOUR turn! You have three challenge levels. Level 1: Can you spot AI-generated images? You'll read descriptions and decide -- real photo or AI-generated. Level 2: Can you tell human writing from AI writing? You'll read text snippets and figure out who wrote them. Level 3: The bias lab. You'll actually test the AI yourself to see if it shows bias."

CN: "现在轮到你了！你有三个挑战级别。第一级：你能识别 AI 生成的图像吗？你会读描述并决定——真照片还是 AI 生成的。第二级：你能区分人类写作和 AI 写作吗？你会读文本片段并找出谁写的。第三级：偏见实验室。你将亲自测试 AI 看它是否表现出偏见。"

EN: "This is a competition between the two of you! Who can score higher on Levels 1 and 2? Open your laptops and go to the Lesson 9 page!"

CN: "这是你们两个人之间的比赛！谁能在第一级和第二级得更高分？打开电脑，进入第九课的页面！"

---

## Hands-on Project / 动手项目 (25 minutes / 分钟)

### Phase 1: Level 1 -- Real or AI? (8 min) *(0:10--0:18)*

**[Switch from slides to monitoring student screens / 从幻灯片切换到巡视学生屏幕]**

EN: "Start with Level 1 -- it should already be open. You'll see 8 questions. For each one, read the description of an image carefully. Then decide: real photo or AI-generated? Click your answer. You'll get an explanation after each question."

CN: "从第一级开始——它应该已经打开了。你会看到 8 个问题。每一个，仔细阅读图像的描述。然后决定：真实照片还是 AI 生成的？点击你的答案。每个问题后你会得到解释。"

EN: "Take your time reading! The clues are in the details."

CN: "慢慢读！线索在细节中。"

**[Give students 8 minutes. Walk around. / 给学生 8 分钟。走动巡视。]**

> **While students work / 学生做题时:**
> - Encourage them to read the full description before answering
> - After a wrong answer, point out the specific clue they missed: "Did you notice the part about six fingers?"
> - Don't give away answers before they guess
>
> **学生做题时注意事项：**
> - 鼓励他们在回答之前阅读完整描述
> - 答错后，指出他们遗漏的具体线索："你注意到六个手指的部分了吗？"
> - 不要在他们猜之前透露答案

EN: *(After most students finish Level 1)* "How did you do? What was the hardest one to spot? Compare your scores!"

CN: *(大多数学生完成第一级后)* "你做得怎么样？哪个最难识别？比较一下你们的分数！"

---

### Phase 2: Level 2 -- Who Wrote This? (7 min) *(0:18--0:25)*

EN: "Click the Level 2 tab. Now you're reading text -- some written by a real person, some written by AI. The question is: which is which? Think about what we talked about -- personality, emotions, perfection."

CN: "点击第二级标签。现在你要读文字——一些是真人写的，一些是 AI 写的。问题是：哪个是哪个？想想我们讨论过的——个性、情感、完美程度。"

**[Give students 7 minutes / 给学生 7 分钟]**

> **Discussion prompt during Level 2 / 第二级期间的讨论提示:**
> EN: After a few questions, ask out loud: "What patterns are you noticing? How does AI writing feel different from human writing?"
> CN: 几个问题后，大声问："你注意到什么规律了？AI 写作和人类写作感觉有什么不同？"

EN: *(After students finish)* "So who scored higher so far? What was your biggest surprise?"

CN: *(学生完成后)* "那么到目前为止谁得分更高？你最大的惊讶是什么？"

**[Let students share briefly / 让学生简短分享]**

---

### Phase 3: Level 3 -- AI Bias Experiment (10 min) *(0:25--0:35)*

EN: "Now for Level 3 -- this one is different. There's no right or wrong answer. Instead, you're going to be researchers. You're going to test the AI for bias."

CN: "现在第三级——这个不一样。没有对错答案。相反，你们要做研究者。你们要测试 AI 是否有偏见。"

EN: "Click the Level 3 tab. You'll see four experiment options. Each one gives you two similar prompts to ask the AI -- like 'describe a nurse' versus 'describe an engineer.' Pick one experiment, then use the chat box to ask both prompts. Compare the AI's answers. Does it make assumptions? Does it describe the two things differently?"

CN: "点击第三级标签。你会看到四个实验选项。每个给你两个相似的提示来问 AI——比如'描述一个护士'对比'描述一个工程师'。选一个实验，然后用聊天框问两个提示。比较 AI 的回答。它是否做了假设？它是否对两件事的描述不同？"

EN: "After you try your experiment, write down what you noticed in the observations box."

CN: "试完实验后，在观察框中写下你注意到的东西。"

**[Give students 10 minutes / 给学生 10 分钟]**

> **Facilitating the bias experiment / 引导偏见实验:**
> EN: Walk around and ask guiding questions:
> - "What gender did the AI assume for the nurse? For the engineer?"
> - "Did you notice any difference in the words the AI used?"
> - "Do you think that's fair? Why or why not?"
>
> CN: 走动并提出引导性问题：
> - "AI 假设护士是什么性别？工程师呢？"
> - "你注意到 AI 使用的词有什么不同吗？"
> - "你觉得这公平吗？为什么？"
>
> **If a student tries multiple experiments / 如果学生尝试多个实验:**
> EN: "Great! The more experiments you try, the more patterns you'll see. Try the 'neighborhoods' one -- that one is really eye-opening."
> CN: "太好了！你尝试的实验越多，你会看到越多的规律。试试'社区'那个——那个真的很开眼。"

> **Teacher tip -- framing bias sensitively / 教师提示——敏感地讨论偏见:**
> EN: If students say things like "the AI is racist" or "the AI is sexist," redirect gently: "It's not that the AI has opinions. It learned from billions of texts written by people, and those texts reflected real biases in our society. The AI is like a mirror -- it reflects what it was shown. The question is: what do we do about it?"
> CN: 如果学生说"AI 是种族歧视的"或"AI 是性别歧视的"，温和地引导："不是 AI 有观点。它从人们写的数十亿文本中学习，那些文本反映了我们社会中真实的偏见。AI 就像一面镜子——它反映它被展示的东西。问题是：我们该怎么办？"

---

## Show & Share / 展示分享 (5 minutes / 分钟) *(0:35--0:40)*

EN: "Alright, let's talk about what you found. First -- scores. Who got more right on Level 1? How about Level 2?"

CN: "好了，让我们谈谈你们发现了什么。首先——分数。谁在第一级答对更多？第二级呢？"

**[Let students compare and celebrate / 让学生比较和庆祝]**

EN: "Now the big question: Level 3. What did you notice in your bias experiment? What did the AI assume?"

CN: "现在是大问题：第三级。你在偏见实验中注意到了什么？AI 假设了什么？"

**[Give each student 1-2 minutes to share observations / 给每个学生 1-2 分钟分享观察]**

EN: "Here's the most important question of the day: Now that you know AI can create fake images, write fake text, and show bias -- how will YOU decide what to trust online going forward?"

CN: "这是今天最重要的问题：既然你知道 AI 可以创建假图片、写假文字、并表现出偏见——你以后将如何决定在网上信任什么？"

**[Wait for thoughtful responses. Guide the discussion. / 等待深思熟虑的回答。引导讨论。]**

> **Possible student responses and follow-ups / 可能的学生回答和后续:**
> - "Check the source" -- "Great! What makes a source reliable?"
> - "Look for AI clues" -- "Yes! Which clues do you think are most useful?"
> - "Ask an adult" -- "Smart! But adults can be fooled too. What else can you do?"
>
> - "检查来源" -- "很好！什么让一个来源可靠？"
> - "寻找 AI 线索" -- "是的！你觉得哪些线索最有用？"
> - "问大人" -- "聪明！但大人也可以被骗。你还能做什么？"

---

## Wrap-up / 课程总结 (2--3 minutes / 分钟) *(0:40--0:43)*

EN: "Today you learned three huge things. One: AI can create very convincing fake images and text. Two: AI writing has patterns you can learn to spot -- too polished, too perfect, no personality. Three: AI can have biases that come from its training data, and those biases can be harmful if we don't catch them."

CN: "今天你们学到了三件重要的事。一：AI 可以创建非常令人信服的假图片和文字。二：AI 写作有你可以学会识别的规律——太精致、太完美、没有个性。三：AI 可能有来自训练数据的偏见，如果我们不注意，这些偏见可能是有害的。"

EN: "The most powerful tool against AI deception is not another AI -- it's YOU. Your brain, your critical thinking, your ability to ask questions and check facts. That's something no AI can replace."

CN: "对抗 AI 欺骗最强大的工具不是另一个 AI——是你。你的大脑、你的批判性思维、你提问和核实事实的能力。这是任何 AI 都无法替代的。"

EN: "Great job today, detectives!"

CN: "今天干得好，侦探们！"

---

## Quick Reference / 快速参考

| Time / 时间 | Section / 环节 | Activity / 活动 |
|---|---|---|
| 0:00--0:02 | Welcome | Slide 1 -- Title, optional deepfake video |
| 0:02--0:04 | Poll | Slide 2 -- Can you always spot AI? |
| 0:04--0:05 | Deepfakes | Slide 3 -- What are deepfakes? |
| 0:05--0:07 | Images | Slide 4 -- Spotting fake images |
| 0:07--0:08 | Text | Slide 5 -- Spotting AI writing |
| 0:08--0:09 | Bias | Slides 6--7 -- AI bias explained |
| 0:09--0:10 | Impact & Mission | Slides 8--10 -- Why it matters, launch |
| 0:10--0:18 | Level 1 | Students do image challenge (8 questions) |
| 0:18--0:25 | Level 2 | Students do text challenge (6 questions) |
| 0:25--0:35 | Level 3 | Students run bias experiments |
| 0:35--0:40 | Share | Compare scores, discuss bias findings |
| 0:40--0:43 | Wrap-up | Key takeaways, critical thinking message |
